{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/openai/shap-e.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:05:38.707985Z","iopub.execute_input":"2025-05-06T15:05:38.708269Z","iopub.status.idle":"2025-05-06T15:05:46.473071Z","shell.execute_reply.started":"2025-05-06T15:05:38.708238Z","shell.execute_reply":"2025-05-06T15:05:46.472153Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/shap-e.git\n  Cloning https://github.com/openai/shap-e.git to /tmp/pip-req-build-awcrbx8n\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/shap-e.git /tmp/pip-req-build-awcrbx8n\n  Resolved https://github.com/openai/shap-e.git to commit 50131012ee11c9d2617f3886c10f000d3c7a3b43\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting clip@ git+https://github.com/openai/CLIP.git (from shap-e==0.0.0)\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-4oe2eidk/clip_7a2dac96f0704f75842485296eec49d0\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-4oe2eidk/clip_7a2dac96f0704f75842485296eec49d0\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (3.18.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (11.1.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (2.5.1+cu124)\nRequirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (0.7.0)\nRequirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (4.11.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (3.7.5)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (0.25.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (1.15.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (1.26.4)\nRequirement already satisfied: blobfile in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (3.0.0)\nRequirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile->shap-e==0.0.0) (3.22.0)\nRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->shap-e==0.0.0) (2.3.0)\nRequirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->shap-e==0.0.0) (5.3.1)\nRequirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (6.3.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (24.2)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (2024.11.6)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.20.1+cu124)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->shap-e==0.0.0) (2.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->shap-e==0.0.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (2025.1.31)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (2025.1.10)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (0.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (4.13.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->shap-e==0.0.0) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->shap-e==0.0.0) (1.17.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.2.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->shap-e==0.0.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap-e==0.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap-e==0.0.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->shap-e==0.0.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->shap-e==0.0.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->shap-e==0.0.0) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom shap_e.diffusion.sample import sample_latents\nfrom shap_e.diffusion.gaussian_diffusion import diffusion_from_config\nfrom shap_e.models.download import load_model, load_config\nfrom shap_e.util.notebooks import decode_latent_mesh\nfrom PIL import Image\nimport os\n\ndef load_image(image_path):\n    \"\"\"Load and preprocess an image for SHAP-E.\"\"\"\n    image = Image.open(image_path).convert('RGB')\n    image = image.resize((224, 224))  # Resize to expected input size\n    return image\n\ndef generate_3d_model(input_type, input_data, output_path, device):\n    \"\"\"Generate a 3D model from text or image input and save it.\"\"\"\n    # Load SHAP-E models\n    xm = load_model('transmitter', device=device)\n    model = load_model('text300M' if input_type == 'text' else 'image300M', device=device)\n    diffusion = diffusion_from_config(load_config('diffusion'))\n\n    # Prepare input\n    batch_size = 1\n    guidance_scale = 15.0\n    if input_type == 'text':\n        prompt = input_data\n    else:\n        prompt = load_image(input_data)\n\n    # Sample latents and generate 3D model\n    latents = sample_latents(\n        batch_size=batch_size,\n        model=model,\n        diffusion=diffusion,\n        guidance_scale=guidance_scale,\n        model_kwargs=dict(texts=[prompt] if input_type == 'text' else dict(images=[prompt])),\n        progress=True,\n        clip_denoised=True,\n        use_fp16=True,\n        use_karras=True,\n        karras_steps=64,\n        sigma_min=1e-3,\n        sigma_max=160,\n        s_churn=0,\n    )\n\n    # Decode latent to mesh and save\n    for i, latent in enumerate(latents):\n        t = decode_latent_mesh(xm, latent).tri_mesh()\n        with open(output_path, 'wb') as f:\n            t.write_ply(f)\n\ndef main():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"Choose input type: (1) Text prompt, (2) Image\")\n    choice = input(\"Enter 1 or 2: \").strip()\n\n    if choice == '1':\n        input_type = 'text'\n        input_data = input(\"Enter text prompt: \").strip()\n        output_filename = 'model_from_text.ply'\n    elif choice == '2':\n        input_type = 'image'\n        input_data = input(\"Enter image file path: \").strip()\n        if not os.path.exists(input_data):\n            print(\"Image file does not exist!\")\n            return\n        output_filename = 'model_from_image.ply'\n    else:\n        print(\"Invalid choice!\")\n        return\n\n    output_path = os.path.join(os.getcwd(), output_filename)\n    print(f\"Generating 3D model... Output will be saved to {output_path}\")\n    generate_3d_model(input_type, input_data, output_path, device)\n    print(f\"3D model saved to {output_path}\")\n\nif __name__ == \"__main__\":\n    main()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:23:17.111452Z","iopub.execute_input":"2025-05-06T16:23:17.112349Z","iopub.status.idle":"2025-05-06T16:24:31.713687Z","shell.execute_reply.started":"2025-05-06T16:23:17.112318Z","shell.execute_reply":"2025-05-06T16:24:31.713047Z"}},"outputs":[{"name":"stdout","text":"Choose input type: (1) Text prompt, (2) Image\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter 1 or 2:  1\nEnter text prompt:  a red chair\n"},{"name":"stdout","text":"Generating 3D model... Output will be saved to /kaggle/working/model_from_text.ply\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868c1fa3db474918962aeea300588960"}},"metadata":{}},{"name":"stdout","text":"3D model saved to /kaggle/working/model_from_text.ply\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Install trimesh (for 3D model conversion)\n!pip install -q trimesh\n\nimport trimesh\n\n# Load your PLY model\nply_path = '/kaggle/working/model_from_text.ply'\nmesh = trimesh.load(ply_path)\n\n# Export to OBJ and STL\nobj_path = '/kaggle/working/model_from_text.obj'\nstl_path = '/kaggle/working/model_from_text.stl'\n\nmesh.export(obj_path)\nmesh.export(stl_path)\n\nprint(f\"Saved OBJ to {obj_path}\")\nprint(f\"Saved STL to {stl_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:24:38.530433Z","iopub.execute_input":"2025-05-06T16:24:38.530750Z","iopub.status.idle":"2025-05-06T16:24:41.790613Z","shell.execute_reply.started":"2025-05-06T16:24:38.530732Z","shell.execute_reply":"2025-05-06T16:24:41.789761Z"}},"outputs":[{"name":"stdout","text":"Saved OBJ to /kaggle/working/model_from_text.obj\nSaved STL to /kaggle/working/model_from_text.stl\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}